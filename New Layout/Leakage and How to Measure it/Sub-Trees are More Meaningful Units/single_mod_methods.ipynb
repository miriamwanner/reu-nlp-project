{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a91a13d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import numpy as np\n",
    "import pickle\n",
    "import conllu\n",
    "import pyconll\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from io import open\n",
    "import os\n",
    "import errno\n",
    "import shutil\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6f2466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method that counts the number of a certain dependency relation between a head pos and dependent pos given a token list\n",
    "def count_of_deprel_tokenlist(token_list, head_pos, dep_pos, deprel):\n",
    "    count = 0\n",
    "    id_to_pos = {}\n",
    "    id_to_pos[0] = 'root'\n",
    "    for token in token_list:\n",
    "        id_to_pos[token['id']] = token['deprel']\n",
    "    for token in token_list:\n",
    "        if token['deprel'] == deprel and token['upos'].lower() == dep_pos and id_to_pos[token['head']] == head_pos:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9932873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that goes through conllu file and finds how many of a certain relation there exists\n",
    "# Load file\n",
    "def count_of_deprel_conllu_file(file, head_pos, dep_pos, deprel):\n",
    "    data_file = open(file, \"r\", encoding=\"utf-8\")\n",
    "\n",
    "    total_count = 0\n",
    "    for token_list in conllu.parse_incr(data_file):\n",
    "        total_count += count_of_deprel_tokenlist(token_list, head_pos, dep_pos, deprel)\n",
    "    \n",
    "    return total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c0ccb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = 'single-mod-outs-nostrip/en_noobjmod_outs.conllu'\n",
    "count_subj_amod = count_of_deprel_conllu_file(my_file, 'nsubj', 'adj', 'amod')\n",
    "count_obj_amod = count_of_deprel_conllu_file(my_file, 'obj', 'adj', 'amod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62ec7678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "237\n"
     ]
    }
   ],
   "source": [
    "print(count_subj_amod)\n",
    "print(count_obj_amod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a48f97a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method that removes any contractions where a modifier has been removed\n",
    "def remove_contractions_with_modifier(token_list):\n",
    "    # get list of ids in a new token list\n",
    "    new_token_ids = []\n",
    "    for token in token_list:\n",
    "        new_token_ids.append(token['id'])\n",
    "        \n",
    "    # if modifier removes a part of a contraction, remove the contraction\n",
    "    contractions_to_remove = []\n",
    "    for token in token_list:\n",
    "        if isinstance(token['id'], tuple):\n",
    "            if (token['id'][0] not in new_token_ids) or (token['id'][2] not in new_token_ids):\n",
    "                contractions_to_remove.append(token['id'])\n",
    "    \n",
    "    # filter the token_list so it includes everything except the contractions we want to remove\n",
    "    new_token_list = token_list.filter(id=lambda x: x not in contractions_to_remove)\n",
    "    return new_token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "431b7db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a TokenList, returns a new TokenList without a given modifier \n",
    "# (dependency relation between head and dependent) (and also without those subtrees)\n",
    "def token_list_no_modifiers(token_list, head_pos, dep_pos, deprel):\n",
    "    ids_to_remove = []\n",
    "    id_to_pos = {}\n",
    "    id_to_pos[0] = 'root'\n",
    "    for token in token_list:\n",
    "        id_to_pos[token['id']] = token['deprel']\n",
    "    for token in token_list:\n",
    "        if token['deprel'] == deprel and token['upos'].lower() == dep_pos and id_to_pos[token['head']] == head_pos:\n",
    "            subtree_ids = ids_in_subtree(token_list, token['id'])\n",
    "            for id_ in subtree_ids:\n",
    "                if id_ not in ids_to_remove:\n",
    "                    ids_to_remove.append(id_)\n",
    "    new_token_list = token_list.filter(id=lambda x: x not in ids_to_remove)\n",
    "    return new_token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38cfdd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bfs algorithm that returns a list of ids in a subtree given the root of the subtree\n",
    "def ids_in_subtree(token_list, root_subtree_id):\n",
    "    visited = []\n",
    "    queue = []\n",
    "    \n",
    "    visited.append(root_subtree_id)\n",
    "    queue.append(root_subtree_id)\n",
    "    \n",
    "    while queue:\n",
    "        s = queue.pop(0)\n",
    "        neighbors = nodes_with_given_head(token_list, s)\n",
    "        \n",
    "        for neighbor in neighbors:\n",
    "            if neighbor not in visited:\n",
    "                visited.append(neighbor)\n",
    "                queue.append(neighbor)\n",
    "    \n",
    "    return visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4823781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of the ids of successors of a given node\n",
    "def nodes_with_given_head(token_list, given_head):\n",
    "    children = []\n",
    "    for token in token_list:\n",
    "        if token['head'] == given_head:\n",
    "            children.append(token['id'])\n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66e0a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a token list, creates the 'text' for the metadata\n",
    "def new_text_from_token_list(token_list):\n",
    "    # need to create the new text for the 'text' field of the metadata\n",
    "    new_text = \"\"\n",
    "    already_added = []\n",
    "    for token in token_list:\n",
    "        if isinstance(token['id'], tuple):\n",
    "            already_added.append(token['id'][0])\n",
    "            already_added.append(token['id'][2])\n",
    "        if token['id'] not in already_added:\n",
    "            if token['misc'] == None:\n",
    "                new_text += token['form'] + \" \"\n",
    "            else:\n",
    "                if 'SpaceAfter' in token['misc'].keys():\n",
    "                    new_text += token['form']\n",
    "                else:\n",
    "                    new_text += token['form'] + \" \"\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bef24fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this fixes the numbers of an altered tree so that they are incremented by one \n",
    "def fixed_numbers(token_lst):\n",
    "    token_list = token_lst\n",
    "    old_to_new_id = {}\n",
    "    old_to_new_id[None] = None\n",
    "    count = 0\n",
    "    \n",
    "    for token in token_list:\n",
    "        if not isinstance(token['id'], tuple):\n",
    "            count += 1\n",
    "            old_id = token['id']\n",
    "            temp1 = count\n",
    "            old_to_new_id[old_id] = temp1\n",
    "            token['id'] = count\n",
    "    \n",
    "    for token in token_list:\n",
    "        # changing all the 'head' fields - except for when it is 0 (the root)\n",
    "        old_head = token['head']\n",
    "        if old_head != 0:\n",
    "            temp2 = old_to_new_id[old_head]\n",
    "            token['head'] = temp2\n",
    "            \n",
    "            \n",
    "        # making all the 'deps' fields be none - since the numbers mess up if I leave it\n",
    "        token['deps'] = None\n",
    "\n",
    "        \n",
    "        # if the id is a range, change the range to the new ids\n",
    "        if isinstance(token['id'], tuple):\n",
    "            id_lst = list(token['id'])\n",
    "            old_first_number = token['id'][0]\n",
    "            old_second_number = token['id'][2]\n",
    "            temp6 = old_to_new_id[old_first_number]\n",
    "            id_lst[0] = temp6\n",
    "            temp7 = old_to_new_id[old_second_number]\n",
    "            id_lst[2] = temp7\n",
    "            token['id'] = tuple(id_lst)\n",
    "            \n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bbe9c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file\n",
    "my_conll_file_location = 'data/UD2/ud-treebanks-v2.8/UD_German-HDT/de_hdt-ud-train.conllu'\n",
    "data_file = open(my_conll_file_location, \"r\", encoding=\"utf-8\")\n",
    "\n",
    "with open(\"de_hdt-ud-train-obj.conllu\", \"w\") as f:\n",
    "    for token_list in conllu.parse_incr(data_file):\n",
    "        # for every token list, remove modifiers, remove contractions with modifiers, and fix the numbers\n",
    "        temp_list = token_list_no_modifiers(token_list, 'obj', 'adj', 'amod')\n",
    "        new_token_list = fixed_numbers(remove_contractions_with_modifier(temp_list))\n",
    "        # set the metadata equal to eachother\n",
    "        new_token_list.metadata = token_list.metadata\n",
    "        # create the new text using the method and set the 'text' field of the metadata to the new text\n",
    "        new_token_list.metadata['text'] = new_text_from_token_list(new_token_list)\n",
    "        \n",
    "        # serialize the token list so it is in conllu format\n",
    "        serialized = new_token_list.serialize()\n",
    "        # write this new serialized data to the file\n",
    "        f.write(serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1a55263",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = 'de_hdt-ud-train-obj.conllu'\n",
    "count_subj_amod = count_of_deprel_conllu_file(my_file, 'nsubj', 'adj', 'amod')\n",
    "count_obj_amod = count_of_deprel_conllu_file(my_file, 'obj', 'adj', 'amod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "828fedba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24960\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(count_subj_amod)\n",
    "print(count_obj_amod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a03bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
